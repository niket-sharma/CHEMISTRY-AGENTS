# CPU Optimization & API Integration Guide

This guide explains how to use Chemistry Agents efficiently on CPU-only systems and with external APIs when GPU resources are not available.

## üîß Quick Start for CPU Users

### 1. Installation (CPU-Only)
```bash
# Install CPU-only version
pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu
pip install -r requirements.txt

# Skip GPU-specific packages if needed
pip install chemistry-agents --no-deps
```

### 2. Basic CPU Usage
```python
from chemistry_agents import PropertyPredictionAgent
from chemistry_agents.agents.base_agent import AgentConfig

# CPU-optimized configuration
config = AgentConfig(
    device="cpu",
    batch_size=4,  # Reduced for CPU
    cpu_optimization=True
)

# Use faster neural networks on CPU
agent = PropertyPredictionAgent(
    config=config,
    model_type="neural_network"  # Faster than transformers on CPU
)

agent.load_model()
results = agent.predict_batch(["CCO", "CC(=O)O", "c1ccccc1"])
```

## üåê External API Integration

### Hugging Face Inference API (Recommended)
```python
import os
from chemistry_agents.agents.base_agent import AgentConfig

# Set up API configuration
config = AgentConfig(
    use_api=True,
    api_provider="huggingface",
    api_key=os.getenv("HUGGINGFACE_API_KEY"),  # Get from https://huggingface.co/settings/tokens
    model_name="DeepChem/ChemBERTa-77M-MLM"
)

agent = PropertyPredictionAgent(config=config)
agent.load_model()  # Connects to API instead of loading local model
```

### API Benefits
- ‚úÖ No local GPU/CPU intensive computation
- ‚úÖ Access to large pre-trained models
- ‚úÖ Always up-to-date models
- ‚úÖ No local storage requirements
- ‚ùå Requires internet connection
- ‚ùå API rate limits
- ‚ùå Potential latency

## ‚òÅÔ∏è Free Cloud Training Options

### 1. Google Colab (Recommended)
```bash
# Generate Colab notebook
python scripts/fine_tune_transformer.py --cloud_training --data_path your_data.csv
```

**Benefits:**
- üÜì Free Tesla T4 GPU
- ‚è∞ 12-hour sessions
- üîÑ Easy to restart
- üì§ Download trained models

### 2. Kaggle Notebooks
- üÜì Free Tesla P100 GPU  
- ‚è∞ 30 GPU hours/week
- üìä Built-in datasets

### 3. Hugging Face Spaces
- üÜì Limited free GPU
- üåê Host models publicly
- üîó Share with others

## ‚ö° CPU Performance Optimization

### 1. Model Selection
```python
# ‚úÖ CPU-Friendly Models
models = [
    "DeepChem/ChemBERTa-5M-MLM",   # Smallest, fastest
    "DeepChem/ChemBERTa-10M-MLM",  # Good balance
]

# ‚ùå Avoid on CPU
avoid = [
    "DeepChem/ChemBERTa-77M-MLM",  # Too large for efficient CPU use
]
```

### 2. Optimal Settings
```python
# CPU-optimized training
python scripts/fine_tune_transformer.py \
    --data_path data.csv \
    --device cpu \
    --batch_size 4 \
    --gradient_accumulation_steps 4 \
    --epochs 5 \
    --model_name "DeepChem/ChemBERTa-10M-MLM"
```

### 3. Performance Tips
```python
import torch

# Limit CPU threads to avoid oversubscription
torch.set_num_threads(4)

# Enable CPU optimizations
config = AgentConfig(
    device="cpu",
    batch_size=4,           # Small batches
    cpu_optimization=True,  # Enable optimizations
    cache_predictions=True  # Cache to avoid recomputation
)

# Use neural networks for fastest CPU inference
agent = PropertyPredictionAgent(
    config=config,
    model_type="neural_network"  # 10-100x faster than transformers on CPU
)
```

## üìä Performance Comparison

| Model Type | CPU Speed | GPU Speed | Accuracy | Memory |
|------------|-----------|-----------|----------|---------|
| Neural Network | ‚úÖ Fast | ‚úÖ Very Fast | ‚≠ê‚≠ê‚≠ê Good | ‚úÖ Low |
| Transformer (Small) | ‚ö†Ô∏è Moderate | ‚úÖ Fast | ‚≠ê‚≠ê‚≠ê‚≠ê Very Good | ‚ö†Ô∏è Medium |
| Transformer (Large) | ‚ùå Slow | ‚úÖ Fast | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent | ‚ùå High |
| Graph Neural Network | ‚ö†Ô∏è Moderate | ‚úÖ Fast | ‚≠ê‚≠ê‚≠ê‚≠ê Very Good | ‚ö†Ô∏è Medium |

## üõ† Troubleshooting

### Common CPU Issues

**1. Out of Memory**
```python
# Reduce batch size
config.batch_size = 2  # or even 1
config.gradient_accumulation_steps = 8  # Maintain effective batch size
```

**2. Slow Training**
```bash
# Use cloud training instead
python scripts/fine_tune_transformer.py --cloud_training
```

**3. Model Loading Errors**
```python
# Ensure CPU-compatible model loading
checkpoint = torch.load(model_path, map_location='cpu')
```

### API Issues

**1. API Key Not Working**
```bash
# Set environment variable
export HUGGINGFACE_API_KEY="your_key_here"

# Or in Python
import os
os.environ["HUGGINGFACE_API_KEY"] = "your_key_here"
```

**2. Rate Limiting**
```python
# Add delays between requests
import time
time.sleep(1)  # Wait 1 second between API calls
```

**3. Model Not Available**
```python
# Check model status
from chemistry_agents.utils.api_integration import HuggingFaceInferenceAPI

api = HuggingFaceInferenceAPI(api_key)
status = api.check_model_status("DeepChem/ChemBERTa-77M-MLM")
print(status)
```

## üí∞ Cost Comparison

| Option | Cost | Speed | Setup | GPU Access |
|--------|------|-------|-------|------------|
| **Local CPU** | $0 | Slow | Easy | ‚ùå |
| **HF API** | $0.50-2/1M tokens | Fast | Easy | ‚úÖ |
| **Google Colab** | $0 (Free tier) | Very Fast | Moderate | ‚úÖ |
| **Colab Pro** | $10/month | Very Fast | Easy | ‚úÖ |
| **AWS SageMaker** | $0.05-0.20/hour | Very Fast | Hard | ‚úÖ |

## üìã Complete CPU Example

```python
#!/usr/bin/env python3
"""Complete CPU-optimized example"""

from chemistry_agents import SolubilityAgent
from chemistry_agents.agents.base_agent import AgentConfig
import json

def main():
    # Load CPU configuration
    config = AgentConfig(
        device="cpu",
        batch_size=4,
        cpu_optimization=True,
        cache_predictions=True
    )
    
    # Initialize with CPU-friendly model
    agent = SolubilityAgent(
        config=config,
        model_type="neural_network"  # Fast on CPU
    )
    
    print("Loading model...")
    agent.load_model()
    
    # Test molecules
    molecules = [
        "CCO",                    # Ethanol
        "CC(=O)O",               # Acetic acid  
        "c1ccccc1",              # Benzene
        "CC(C)C1=CC=C(C=C1)C(C)C(=O)O"  # Ibuprofen
    ]
    
    print("Making predictions...")
    results = agent.predict_batch(molecules)
    
    # Display results
    for result in results:
        if result.additional_info and "error" not in result.additional_info:
            solubility_class = result.additional_info.get("solubility_class")
            print(f"{result.smiles}: {result.prediction:.2f} log S ({solubility_class})")
    
    print("‚úÖ CPU prediction complete!")

if __name__ == "__main__":
    main()
```

## üöÄ Next Steps

1. **For occasional use**: Use API integration
2. **For development**: Local CPU with neural networks  
3. **For training**: Google Colab or cloud platforms
4. **For production**: Consider cloud GPU instances

## üìû Support

- **Issues**: [GitHub Issues](https://github.com/yourusername/chemistry-agents/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/chemistry-agents/discussions)
- **API Docs**: [Hugging Face Docs](https://huggingface.co/docs/api-inference/)

---
**üí° Remember**: CPU training is possible but slow. For best results, use cloud training and CPU for inference only.